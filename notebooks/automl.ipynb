{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4733</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.65</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6424</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8770</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.36</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4493</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.21</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table  price     x     y     z\n",
       "0   1.10      Ideal     H     SI2   62.0   55.0   4733  6.61  6.65  4.11\n",
       "1   1.29      Ideal     H     SI1   62.6   56.0   6424  6.96  6.93  4.35\n",
       "2   1.20    Premium     I     SI1   61.1   58.0   5510  6.88  6.80  4.18\n",
       "3   1.50      Ideal     F     SI1   60.9   56.0   8770  7.43  7.36  4.50\n",
       "4   0.90  Very Good     F     VS2   61.7   57.0   4493  6.17  6.21  3.82"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TabularDataset(f'../data/01_raw/diamonds.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5000.00000\n",
       "mean      3925.53940\n",
       "std       3975.45212\n",
       "min         -1.00000\n",
       "25%        936.00000\n",
       "50%       2392.50000\n",
       "75%       5369.25000\n",
       "max      18787.00000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = 'price'\n",
    "data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     4990.000000\n",
       "mean      3933.408216\n",
       "std       3975.541768\n",
       "min        351.000000\n",
       "25%        942.000000\n",
       "50%       2398.000000\n",
       "75%       5377.500000\n",
       "max      18787.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data[data['price']>0]\n",
    "data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_data,test_data= train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./autogluon_models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       4.86 GB / 15.96 GB (30.5%)\n",
      "Disk Space Avail:   30.20 GB / 222.97 GB (13.5%)\n",
      "===================================================\n",
      "Train Data Rows:    3992\n",
      "Train Data Columns: 9\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18787, 351, 3960.64755, 4008.67444)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4981.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.87 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('object', []) : 3 | ['cut', 'color', 'clarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['cut', 'color', 'clarity']\n",
      "\t\t('float', [])    : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.20 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.125250501002004, Train Rows: 3492, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1398.8815\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1438.1174\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 622.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-621.5082\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.87s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-744.7254\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-802.1102\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-621.6143\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-763.5691\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-595.9581\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-736.6945\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-610.9624\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-943.5211\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.44, 'NeuralNetTorch': 0.28, 'CatBoost': 0.2, 'LightGBMXT': 0.08}\n",
      "\t-572.062\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 52.11s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,path='./autogluon_models').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-572.061991</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.047981</td>\n",
       "      <td>41.745703</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-595.958082</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>8.258409</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>8.258409</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-610.962441</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>11.280308</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>11.280308</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-621.508194</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>1.865681</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>1.865681</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-621.614346</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>20.321305</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>20.321305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-736.694499</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-744.725386</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.761105</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.761105</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-763.569144</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.847920</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.847920</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-802.110205</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>2.090674</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>2.090674</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-943.521076</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.596125</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>1.596125</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-1398.881455</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>3.255899</td>\n",
       "      <td>0.030351</td>\n",
       "      <td>3.255899</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-1438.117428</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    score_val              eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -572.061991  root_mean_squared_error       0.047981   \n",
       "1       NeuralNetFastAI  -595.958082  root_mean_squared_error       0.014003   \n",
       "2        NeuralNetTorch  -610.962441  root_mean_squared_error       0.009002   \n",
       "3            LightGBMXT  -621.508194  root_mean_squared_error       0.018001   \n",
       "4              CatBoost  -621.614346  root_mean_squared_error       0.005973   \n",
       "5               XGBoost  -736.694499  root_mean_squared_error       0.009000   \n",
       "6              LightGBM  -744.725386  root_mean_squared_error       0.008002   \n",
       "7         ExtraTreesMSE  -763.569144  root_mean_squared_error       0.063002   \n",
       "8       RandomForestMSE  -802.110205  root_mean_squared_error       0.062000   \n",
       "9         LightGBMLarge  -943.521076  root_mean_squared_error       0.013000   \n",
       "10       KNeighborsUnif -1398.881455  root_mean_squared_error       0.030351   \n",
       "11       KNeighborsDist -1438.117428  root_mean_squared_error       0.030002   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   41.745703                0.001003           0.020000            2   \n",
       "1    8.258409                0.014003           8.258409            1   \n",
       "2   11.280308                0.009002          11.280308            1   \n",
       "3    1.865681                0.018001           1.865681            1   \n",
       "4   20.321305                0.005973          20.321305            1   \n",
       "5    0.743481                0.009000           0.743481            1   \n",
       "6    0.761105                0.008002           0.761105            1   \n",
       "7    0.847920                0.063002           0.847920            1   \n",
       "8    2.090674                0.062000           2.090674            1   \n",
       "9    1.596125                0.013000           1.596125            1   \n",
       "10   3.255899                0.030351           3.255899            1   \n",
       "11   0.008998                0.030002           0.008998            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         12  \n",
       "1        True          8  \n",
       "2        True         10  \n",
       "3        True          3  \n",
       "4        True          6  \n",
       "5        True          9  \n",
       "6        True          4  \n",
       "7        True          7  \n",
       "8        True          5  \n",
       "9        True         11  \n",
       "10       True          1  \n",
       "11       True          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some feature engineering adding some ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>encoded_cut</th>\n",
       "      <th>encoded_clarity</th>\n",
       "      <th>encoded_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4733</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.65</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>62.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6424</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20</td>\n",
       "      <td>61.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.50</td>\n",
       "      <td>60.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8770</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.36</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>61.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4493</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.38</td>\n",
       "      <td>62.3</td>\n",
       "      <td>53.3</td>\n",
       "      <td>832</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.69</td>\n",
       "      <td>2.91</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.33</td>\n",
       "      <td>61.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>927</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.42</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.25</td>\n",
       "      <td>62.1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5980</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.31</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>802</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.27</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.30</td>\n",
       "      <td>61.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>655</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.39</td>\n",
       "      <td>2.66</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4990 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      carat  depth  table  price     x     y     z  encoded_cut  \\\n",
       "0      1.10   62.0   55.0   4733  6.61  6.65  4.11            4   \n",
       "1      1.29   62.6   56.0   6424  6.96  6.93  4.35            4   \n",
       "2      1.20   61.1   58.0   5510  6.88  6.80  4.18            3   \n",
       "3      1.50   60.9   56.0   8770  7.43  7.36  4.50            4   \n",
       "4      0.90   61.7   57.0   4493  6.17  6.21  3.82            2   \n",
       "...     ...    ...    ...    ...   ...   ...   ...          ...   \n",
       "4995   0.38   62.3   53.3    832  4.65  4.69  2.91            4   \n",
       "4996   0.33   61.3   59.0    927  4.45  4.42  2.72            3   \n",
       "4997   1.25   62.1   56.0   5980  6.81  6.84  4.24            4   \n",
       "4998   0.31   62.9   58.0    802  4.31  4.27  2.70            3   \n",
       "4999   0.30   61.2   57.0    655  4.30  4.39  2.66            4   \n",
       "\n",
       "      encoded_clarity  encoded_color  \n",
       "0                   1              2  \n",
       "1                   2              2  \n",
       "2                   2              1  \n",
       "3                   2              4  \n",
       "4                   3              4  \n",
       "...               ...            ...  \n",
       "4995                5              2  \n",
       "4996                5              3  \n",
       "4997                5              0  \n",
       "4998                3              4  \n",
       "4999                6              2  \n",
       "\n",
       "[4990 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the order for each categorical variable (cut, color, clarity) from worst to best\n",
    "cut_order= {'Fair': 0, 'Good': 1, 'Very Good': 2, 'Premium': 3, 'Ideal': 4}\n",
    "clarity_order={'I1':0,'SI2':1, 'SI1':2, 'VS2':3, 'VS1':4, 'VVS2':5, 'VVS1':6, 'IF':7}\n",
    "color_order={'J':0, 'I':1, 'H':2, 'G':3, 'F':4, 'E':5,'D':6}\n",
    "# Label encoding\n",
    "data['encoded_cut'] = data['cut'].map(cut_order)\n",
    "data['encoded_clarity'] = data['clarity'].map(clarity_order)\n",
    "data['encoded_color'] = data['color'].map(color_order)\n",
    "#We drop the columns cut, clarity and color\n",
    "data=data.drop(['cut'],axis=1)\n",
    "data=data.drop(['clarity'],axis=1)\n",
    "data=data.drop(['color'],axis=1)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data= train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./autogluon_models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       4.57 GB / 15.96 GB (28.6%)\n",
      "Disk Space Avail:   28.50 GB / 222.97 GB (12.8%)\n",
      "===================================================\n",
      "Train Data Rows:    3992\n",
      "Train Data Columns: 9\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18787, 351, 3960.64755, 4008.67444)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4681.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.125250501002004, Train Rows: 3492, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1101.9475\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1067.7902\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-604.451\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-651.663\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-740.9376\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.63s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-606.1008\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-692.0599\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-624.7365\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-678.0018\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-618.8222\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-741.0819\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 0.316, 'CatBoost': 0.316, 'NeuralNetTorch': 0.211, 'NeuralNetFastAI': 0.158}\n",
      "\t-585.5816\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 23.0s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,path='./autogluon_models').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-585.581590</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.029006</td>\n",
       "      <td>16.811885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019029</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-604.450974</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.886145</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-606.100786</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>2.175210</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>2.175210</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-618.822224</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>10.119736</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>10.119736</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-624.736548</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>3.611764</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>3.611764</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-651.663003</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.622999</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.622999</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-678.001811</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.547262</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.547262</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-692.059883</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.061998</td>\n",
       "      <td>0.787887</td>\n",
       "      <td>0.061998</td>\n",
       "      <td>0.787887</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-740.937559</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>1.630902</td>\n",
       "      <td>0.108999</td>\n",
       "      <td>1.630902</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-741.081924</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.366408</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.366408</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-1067.790155</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>0.010997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-1101.947472</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    score_val              eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -585.581590  root_mean_squared_error       0.029006   \n",
       "1            LightGBMXT  -604.450974  root_mean_squared_error       0.009004   \n",
       "2              CatBoost  -606.100786  root_mean_squared_error       0.002002   \n",
       "3        NeuralNetTorch  -618.822224  root_mean_squared_error       0.009002   \n",
       "4       NeuralNetFastAI  -624.736548  root_mean_squared_error       0.008999   \n",
       "5              LightGBM  -651.663003  root_mean_squared_error       0.001999   \n",
       "6               XGBoost  -678.001811  root_mean_squared_error       0.003000   \n",
       "7         ExtraTreesMSE  -692.059883  root_mean_squared_error       0.061998   \n",
       "8       RandomForestMSE  -740.937559  root_mean_squared_error       0.108999   \n",
       "9         LightGBMLarge  -741.081924  root_mean_squared_error       0.003000   \n",
       "10       KNeighborsDist -1067.790155  root_mean_squared_error       0.026001   \n",
       "11       KNeighborsUnif -1101.947472  root_mean_squared_error       0.065000   \n",
       "\n",
       "     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   16.811885                0.000000           0.019029            2   \n",
       "1    0.886145                0.009004           0.886145            1   \n",
       "2    2.175210                0.002002           2.175210            1   \n",
       "3   10.119736                0.009002          10.119736            1   \n",
       "4    3.611764                0.008999           3.611764            1   \n",
       "5    0.622999                0.001999           0.622999            1   \n",
       "6    0.547262                0.003000           0.547262            1   \n",
       "7    0.787887                0.061998           0.787887            1   \n",
       "8    1.630902                0.108999           1.630902            1   \n",
       "9    1.366408                0.003000           1.366408            1   \n",
       "10   0.010997                0.026001           0.010997            1   \n",
       "11   0.014001                0.065000           0.014001            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         12  \n",
       "1        True          3  \n",
       "2        True          6  \n",
       "3        True         10  \n",
       "4        True          8  \n",
       "5        True          4  \n",
       "6        True          9  \n",
       "7        True          7  \n",
       "8        True          5  \n",
       "9        True         11  \n",
       "10       True          2  \n",
       "11       True          1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "Presets specified: ['interpretable']\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\common\\utils\\utils.py:73: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2825: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('autogluon')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./autogluon_models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       4.73 GB / 15.96 GB (29.6%)\n",
      "Disk Space Avail:   26.11 GB / 222.97 GB (11.7%)\n",
      "===================================================\n",
      "Train Data Rows:    3992\n",
      "Train Data Columns: 9\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18787, 351, 3960.64755, 4008.67444)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLInterpretablePipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4841.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.125250501002004, Train Rows: 3492, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'IM_RULEFIT': [{'max_rules': 7}, {'max_rules': 12}, {'max_rules': 18}],\n",
      "\t'IM_FIGS': [{'max_rules': 6}, {'max_rules': 10}, {'max_rules': 15}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RuleFit ...\n",
      "\t-1766.197\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RuleFit_2 ...\n",
      "\t-1460.5973\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RuleFit_3 ...\n",
      "\t-1241.984\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: Figs ...\n",
      "\t-1305.267\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: Figs_2 ...\n",
      "\t-1166.7969\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: Figs_3 ...\n",
      "\t-1054.0606\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 39.5s ... Best model: \"Figs_3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,path='./autogluon_models').fit(train_data,presets='interpretable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Figs_3</td>\n",
       "      <td>-1054.060575</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.238026</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.238026</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Figs_2</td>\n",
       "      <td>-1166.796866</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.128997</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.128997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RuleFit_3</td>\n",
       "      <td>-1241.984010</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>15.064929</td>\n",
       "      <td>0.026000</td>\n",
       "      <td>15.064929</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Figs</td>\n",
       "      <td>-1305.266950</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.078997</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.078997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RuleFit_2</td>\n",
       "      <td>-1460.597310</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>11.482945</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>11.482945</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RuleFit</td>\n",
       "      <td>-1766.197049</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>12.323115</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>12.323115</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model    score_val              eval_metric  pred_time_val   fit_time  \\\n",
       "0     Figs_3 -1054.060575  root_mean_squared_error       0.003000   0.238026   \n",
       "1     Figs_2 -1166.796866  root_mean_squared_error       0.002030   0.128997   \n",
       "2  RuleFit_3 -1241.984010  root_mean_squared_error       0.026000  15.064929   \n",
       "3       Figs -1305.266950  root_mean_squared_error       0.001000   0.078997   \n",
       "4  RuleFit_2 -1460.597310  root_mean_squared_error       0.016999  11.482945   \n",
       "5    RuleFit -1766.197049  root_mean_squared_error       0.010000  12.323115   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                0.003000           0.238026            1       True   \n",
       "1                0.002030           0.128997            1       True   \n",
       "2                0.026000          15.064929            1       True   \n",
       "3                0.001000           0.078997            1       True   \n",
       "4                0.016999          11.482945            1       True   \n",
       "5                0.010000          12.323115            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          6  \n",
       "1          5  \n",
       "2          3  \n",
       "3          4  \n",
       "4          2  \n",
       "5          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./autogluon_models\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          4\n",
      "Memory Avail:       4.68 GB / 15.96 GB (29.3%)\n",
      "Disk Space Avail:   25.68 GB / 222.97 GB (11.5%)\n",
      "===================================================\n",
      "Train Data Rows:    3992\n",
      "Train Data Columns: 9\n",
      "Label Column:       price\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (18787, 351, 3960.64755, 4008.67444)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4792.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 6 | ['carat', 'depth', 'table', 'x', 'y', ...]\n",
      "\t\t('int', [])   : 3 | ['encoded_cut', 'encoded_clarity', 'encoded_color']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.125250501002004, Train Rows: 3492, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'GBM': {},\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'RF': {},\n",
      "\t'XT': {},\n",
      "\t'KNN': {},\n",
      "\t'LR': {},\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'AG_AUTOMM': {},\n",
      "\t'FT_TRANSFORMER': {},\n",
      "\t'FASTTEXT': {},\n",
      "\t'VW': {},\n",
      "\t'AG_TEXT_NN': {},\n",
      "\t'AG_IMAGE_NN': {},\n",
      "}\n",
      "Fitting 14 L1 models ...\n",
      "Fitting model: KNeighbors ...\n",
      "\t-1101.9475\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-651.663\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForest ...\n",
      "\t-740.9376\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.83s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-606.1008\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTrees ...\n",
      "\t-692.0599\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-624.7365\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-678.0018\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LinearModel ...\n",
      "\t-1647.4119\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-618.8222\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: VowpalWabbit ...\n",
      "\tWarning: Exception caused VowpalWabbit to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import vowpalwabbit` failed.\n",
      "A quick tip is to install via `pip install vowpalwabbit>=9,<9.10\n",
      "Fitting model: MultiModalPredictor ...\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:51: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  Bool8 = np.bool8\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:54: DeprecationWarning: `np.object0` is a deprecated alias for ``np.object0` is a deprecated alias for `np.object_`. `object` can be used instead.  (Deprecated NumPy 1.24)`.  (Deprecated NumPy 1.24)\n",
      "  Object0 = np.object0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:66: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  Int0 = np.int0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:80: DeprecationWarning: `np.uint0` is a deprecated alias for `np.uintp`.  (Deprecated NumPy 1.24)\n",
      "  UInt0 = np.uint0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:107: DeprecationWarning: `np.void0` is a deprecated alias for `np.void`.  (Deprecated NumPy 1.24)\n",
      "  Void0 = np.void0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:112: DeprecationWarning: `np.bytes0` is a deprecated alias for `np.bytes_`.  (Deprecated NumPy 1.24)\n",
      "  Bytes0 = np.bytes0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\nptyping\\typing_.py:114: DeprecationWarning: `np.str0` is a deprecated alias for `np.str_`.  (Deprecated NumPy 1.24)\n",
      "  Str0 = np.str0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\fabric\\__init__.py:40: Deprecated call to `pkg_resources.declare_namespace('lightning.fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2309: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\__init__.py:37: Deprecated call to `pkg_resources.declare_namespace('lightning.pytorch')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\pkg_resources\\__init__.py:2309: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "\tWarning: Exception caused MultiModalPredictor to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit MultiModalPredictorModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit MultiModalPredictorModel. Consider using a machine with more GPUs.\n",
      "Fitting model: FTTransformer ...\n",
      "WARNING: Training FTTransformer on CPU (no GPU specified). This could take a long time. Use GPU to speed up training.\n",
      "INFO: Seed set to 0\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\multimodal\\utils\\environment.py:131: UserWarning: Only CPU is detected in the instance. This may result in slow speed for MultiModalPredictor. Consider using an instance with GPU support.\n",
      "  warnings.warn(\n",
      "INFO: GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: \n",
      "  | Name              | Type             | Params\n",
      "-------------------------------------------------------\n",
      "0 | model             | FT_Transformer   | 821 K \n",
      "1 | validation_metric | MeanSquaredError | 0     \n",
      "2 | loss_func         | MSELoss          | 0     \n",
      "-------------------------------------------------------\n",
      "821 K     Trainable params\n",
      "0         Non-trainable params\n",
      "821 K     Total params\n",
      "3.286     Total estimated model params size (MB)\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "INFO: Epoch 0, global step 14: 'val_root_mean_squared_error' reached 0.31198 (best 0.31198), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=0-step=14.ckpt' as top 3\n",
      "INFO: Epoch 0, global step 28: 'val_root_mean_squared_error' reached 0.23846 (best 0.23846), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=0-step=28.ckpt' as top 3\n",
      "INFO: Epoch 1, global step 42: 'val_root_mean_squared_error' reached 0.20431 (best 0.20431), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=1-step=42.ckpt' as top 3\n",
      "INFO: Epoch 1, global step 56: 'val_root_mean_squared_error' reached 0.20019 (best 0.20019), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=1-step=56.ckpt' as top 3\n",
      "INFO: Epoch 2, global step 70: 'val_root_mean_squared_error' reached 0.18198 (best 0.18198), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=2-step=70.ckpt' as top 3\n",
      "INFO: Epoch 2, global step 84: 'val_root_mean_squared_error' reached 0.17388 (best 0.17388), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=2-step=84.ckpt' as top 3\n",
      "INFO: Epoch 3, global step 98: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 3, global step 112: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 4, global step 126: 'val_root_mean_squared_error' reached 0.17954 (best 0.17388), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=4-step=126.ckpt' as top 3\n",
      "INFO: Epoch 4, global step 140: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 5, global step 154: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 5, global step 168: 'val_root_mean_squared_error' reached 0.17555 (best 0.17388), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=5-step=168.ckpt' as top 3\n",
      "INFO: Epoch 6, global step 182: 'val_root_mean_squared_error' reached 0.16453 (best 0.16453), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=6-step=182.ckpt' as top 3\n",
      "INFO: Epoch 6, global step 196: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 7, global step 210: 'val_root_mean_squared_error' reached 0.17416 (best 0.16453), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=7-step=210.ckpt' as top 3\n",
      "INFO: Epoch 7, global step 224: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 8, global step 238: 'val_root_mean_squared_error' reached 0.16488 (best 0.16453), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=8-step=238.ckpt' as top 3\n",
      "INFO: Epoch 8, global step 252: 'val_root_mean_squared_error' reached 0.14853 (best 0.14853), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=8-step=252.ckpt' as top 3\n",
      "INFO: Epoch 9, global step 266: 'val_root_mean_squared_error' reached 0.15333 (best 0.14853), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=9-step=266.ckpt' as top 3\n",
      "INFO: Epoch 9, global step 280: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 10, global step 294: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 10, global step 308: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 11, global step 322: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 11, global step 336: 'val_root_mean_squared_error' reached 0.14955 (best 0.14853), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=11-step=336.ckpt' as top 3\n",
      "INFO: Epoch 12, global step 350: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 12, global step 364: 'val_root_mean_squared_error' reached 0.15126 (best 0.14853), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=12-step=364.ckpt' as top 3\n",
      "INFO: Epoch 13, global step 378: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 13, global step 392: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 14, global step 406: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 14, global step 420: 'val_root_mean_squared_error' reached 0.14349 (best 0.14349), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=14-step=420.ckpt' as top 3\n",
      "INFO: Epoch 15, global step 434: 'val_root_mean_squared_error' reached 0.14773 (best 0.14349), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=15-step=434.ckpt' as top 3\n",
      "INFO: Epoch 15, global step 448: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 16, global step 462: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 16, global step 476: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 17, global step 490: 'val_root_mean_squared_error' reached 0.14450 (best 0.14349), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=17-step=490.ckpt' as top 3\n",
      "INFO: Epoch 17, global step 504: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 18, global step 518: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 18, global step 532: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 19, global step 546: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 19, global step 560: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 20, global step 574: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 20, global step 588: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 21, global step 602: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 21, global step 616: 'val_root_mean_squared_error' reached 0.14602 (best 0.14349), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=21-step=616.ckpt' as top 3\n",
      "INFO: Epoch 22, global step 630: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 22, global step 644: 'val_root_mean_squared_error' reached 0.14440 (best 0.14349), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=22-step=644.ckpt' as top 3\n",
      "INFO: Epoch 23, global step 658: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 23, global step 672: 'val_root_mean_squared_error' reached 0.13863 (best 0.13863), saving model to 'C:\\\\Users\\\\super\\\\OneDrive\\\\AI experiments\\\\xtream-challenge\\\\xtream-ai-assignment-engineer\\\\notebooks\\\\autogluon_models\\\\models\\\\FTTransformer\\\\automm_model\\\\epoch=23-step=672.ckpt' as top 3\n",
      "INFO: Epoch 24, global step 686: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 24, global step 700: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 25, global step 714: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 25, global step 728: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 26, global step 742: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 26, global step 756: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 27, global step 770: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 27, global step 784: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 28, global step 798: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 28, global step 812: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 29, global step 826: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 29, global step 840: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 30, global step 854: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 30, global step 868: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 31, global step 882: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 31, global step 896: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 32, global step 910: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 32, global step 924: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 33, global step 938: 'val_root_mean_squared_error' was not in top 3\n",
      "INFO: Epoch 33, global step 952: 'val_root_mean_squared_error' was not in top 3\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "\t-577.5513\t = Validation score   (-root_mean_squared_error)\n",
      "\t97.94s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: TextPredictor ...\n",
      "\tWarning: Exception caused TextPredictor to fail during training... Skipping this model.\n",
      "\t\tThe total system num_gpus=0 is less than minimum num_gpus=1 to fit TextPredictorModel. Consider using a machine with more GPUs.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 847, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 528, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 759, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 704, in _calculate_total_resources\n",
      "    system_num_gpus >= minimum_model_num_gpus\n",
      "AssertionError: The total system num_gpus=0 is less than minimum num_gpus=1 to fit TextPredictorModel. Consider using a machine with more GPUs.\n",
      "Fitting model: ImagePredictor ...\n",
      "\tNo valid features to train ImagePredictor... Skipping this model.\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'FTTransformer': 0.625, 'CatBoost': 0.25, 'NeuralNetTorch': 0.083, 'LightGBM': 0.042}\n",
      "\t-567.1979\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 131.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label,path='./autogluon_models').fit(train_data,hyperparameters={\n",
    "  \"GBM\": {},\n",
    "  \"CAT\": {},\n",
    "  \"XGB\": {},\n",
    "  \"RF\": {},\n",
    "  \"XT\": {},\n",
    "  \"KNN\": {},\n",
    "  \"LR\": {},\n",
    "  \"NN_TORCH\": {},\n",
    "  \"FASTAI\": {},\n",
    "  \"AG_AUTOMM\": {},\n",
    "  \"FT_TRANSFORMER\": {},\n",
    "  \"FASTTEXT\": {},\n",
    "  \"VW\": {},\n",
    "  \"AG_TEXT_NN\": {},\n",
    "  \"AG_IMAGE_NN\": {},\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-567.197874</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.132547</td>\n",
       "      <td>113.222946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FTTransformer</td>\n",
       "      <td>-577.551320</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.121998</td>\n",
       "      <td>97.938707</td>\n",
       "      <td>0.121998</td>\n",
       "      <td>97.938707</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-606.100786</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>2.399503</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>2.399503</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-618.822224</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>12.287737</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>12.287737</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-624.736548</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>3.899204</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>3.899204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-651.663003</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-678.001811</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>-692.059883</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>0.848995</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>0.848995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-740.937559</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>1.831770</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>1.831770</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>-1101.947472</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearModel</td>\n",
       "      <td>-1647.411876</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.298997</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.298997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    score_val              eval_metric  pred_time_val  \\\n",
       "0   WeightedEnsemble_L2  -567.197874  root_mean_squared_error       0.132547   \n",
       "1         FTTransformer  -577.551320  root_mean_squared_error       0.121998   \n",
       "2              CatBoost  -606.100786  root_mean_squared_error       0.001549   \n",
       "3        NeuralNetTorch  -618.822224  root_mean_squared_error       0.007000   \n",
       "4       NeuralNetFastAI  -624.736548  root_mean_squared_error       0.012000   \n",
       "5              LightGBM  -651.663003  root_mean_squared_error       0.001999   \n",
       "6               XGBoost  -678.001811  root_mean_squared_error       0.003998   \n",
       "7            ExtraTrees  -692.059883  root_mean_squared_error       0.064001   \n",
       "8          RandomForest  -740.937559  root_mean_squared_error       0.064000   \n",
       "9            KNeighbors -1101.947472  root_mean_squared_error       0.042998   \n",
       "10          LinearModel -1647.411876  root_mean_squared_error       0.006433   \n",
       "\n",
       "      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   113.222946                0.000000           0.018998            2   \n",
       "1    97.938707                0.121998          97.938707            1   \n",
       "2     2.399503                0.001549           2.399503            1   \n",
       "3    12.287737                0.007000          12.287737            1   \n",
       "4     3.899204                0.012000           3.899204            1   \n",
       "5     0.578001                0.001999           0.578001            1   \n",
       "6     0.741611                0.003998           0.741611            1   \n",
       "7     0.848995                0.064001           0.848995            1   \n",
       "8     1.831770                0.064000           1.831770            1   \n",
       "9     0.012001                0.042998           0.012001            1   \n",
       "10    0.298997                0.006433           0.298997            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         11  \n",
       "1        True         10  \n",
       "2        True          4  \n",
       "3        True          9  \n",
       "4        True          6  \n",
       "5        True          2  \n",
       "6        True          7  \n",
       "7        True          5  \n",
       "8        True          3  \n",
       "9        True          1  \n",
       "10       True          8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: c:\\Users\\super\\OneDrive\\AI experiments\\xtream-challenge\\xtream-ai-assignment-engineer\\notebooks\\autogluon_models\\models\\FTTransformer\\automm_model\\model.ckpt\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -821.8747657000241,\n",
       " 'mean_squared_error': -675478.1304944695,\n",
       " 'mean_absolute_error': -341.52508612195095,\n",
       " 'r2': 0.9541495442390442,\n",
       " 'pearsonr': 0.9768153455273266,\n",
       " 'median_absolute_error': -152.60198974609375}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load pretrained checkpoint: c:\\Users\\super\\OneDrive\\AI experiments\\xtream-challenge\\xtream-ai-assignment-engineer\\notebooks\\autogluon_models\\models\\FTTransformer\\automm_model\\model.ckpt\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-677.475065</td>\n",
       "      <td>-678.001811</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.003998</td>\n",
       "      <td>0.741611</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-797.135186</td>\n",
       "      <td>-606.100786</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>2.399503</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>2.399503</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-797.536655</td>\n",
       "      <td>-740.937559</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.181001</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>1.831770</td>\n",
       "      <td>0.181001</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>1.831770</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-803.122690</td>\n",
       "      <td>-651.663003</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>-814.363878</td>\n",
       "      <td>-692.059883</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.198766</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>0.848995</td>\n",
       "      <td>0.198766</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>0.848995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-821.874766</td>\n",
       "      <td>-567.197874</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.371995</td>\n",
       "      <td>0.132547</td>\n",
       "      <td>113.222946</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FTTransformer</td>\n",
       "      <td>-854.873409</td>\n",
       "      <td>-577.551320</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.121998</td>\n",
       "      <td>97.938707</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.121998</td>\n",
       "      <td>97.938707</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-888.878865</td>\n",
       "      <td>-618.822224</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>12.287737</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>12.287737</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-890.219351</td>\n",
       "      <td>-624.736548</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>3.899204</td>\n",
       "      <td>0.046998</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>3.899204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>-1160.202577</td>\n",
       "      <td>-1101.947472</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.188999</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.188999</td>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LinearModel</td>\n",
       "      <td>-1978.641991</td>\n",
       "      <td>-1647.411876</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.298997</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.298997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model   score_test    score_val              eval_metric  \\\n",
       "0               XGBoost  -677.475065  -678.001811  root_mean_squared_error   \n",
       "1              CatBoost  -797.135186  -606.100786  root_mean_squared_error   \n",
       "2          RandomForest  -797.536655  -740.937559  root_mean_squared_error   \n",
       "3              LightGBM  -803.122690  -651.663003  root_mean_squared_error   \n",
       "4            ExtraTrees  -814.363878  -692.059883  root_mean_squared_error   \n",
       "5   WeightedEnsemble_L2  -821.874766  -567.197874  root_mean_squared_error   \n",
       "6         FTTransformer  -854.873409  -577.551320  root_mean_squared_error   \n",
       "7        NeuralNetTorch  -888.878865  -618.822224  root_mean_squared_error   \n",
       "8       NeuralNetFastAI  -890.219351  -624.736548  root_mean_squared_error   \n",
       "9            KNeighbors -1160.202577 -1101.947472  root_mean_squared_error   \n",
       "10          LinearModel -1978.641991 -1647.411876  root_mean_squared_error   \n",
       "\n",
       "    pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0         0.027999       0.003998    0.741611                 0.027999   \n",
       "1         0.017000       0.001549    2.399503                 0.017000   \n",
       "2         0.181001       0.064000    1.831770                 0.181001   \n",
       "3         0.004996       0.001999    0.578001                 0.004996   \n",
       "4         0.198766       0.064001    0.848995                 0.198766   \n",
       "5         0.371995       0.132547  113.222946                 0.002999   \n",
       "6         0.338000       0.121998   97.938707                 0.338000   \n",
       "7         0.009001       0.007000   12.287737                 0.009001   \n",
       "8         0.046998       0.012000    3.899204                 0.046998   \n",
       "9         0.188999       0.042998    0.012001                 0.188999   \n",
       "10        0.011001       0.006433    0.298997                 0.011001   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.003998           0.741611            1       True   \n",
       "1                 0.001549           2.399503            1       True   \n",
       "2                 0.064000           1.831770            1       True   \n",
       "3                 0.001999           0.578001            1       True   \n",
       "4                 0.064001           0.848995            1       True   \n",
       "5                 0.000000           0.018998            2       True   \n",
       "6                 0.121998          97.938707            1       True   \n",
       "7                 0.007000          12.287737            1       True   \n",
       "8                 0.012000           3.899204            1       True   \n",
       "9                 0.042998           0.012001            1       True   \n",
       "10                0.006433           0.298997            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           7  \n",
       "1           4  \n",
       "2           3  \n",
       "3           2  \n",
       "4           5  \n",
       "5          11  \n",
       "6          10  \n",
       "7           9  \n",
       "8           6  \n",
       "9           1  \n",
       "10          8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m train_X \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      7\u001b[0m train_Y\u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m \u001b[43mregr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lineartree\\lineartree.py:715\u001b[0m, in \u001b[0;36mLinearBoostRegressor.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_targets \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    714\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 715\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\lineartree\\_classes.py:916\u001b[0m, in \u001b[0;36m_LinearBoosting._fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators):\n\u001b[0;32m    915\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_estimator)\n\u001b[1;32m--> 916\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    919\u001b[0m         pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n",
      "File \u001b[1;32mc:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\linear_model\\_base.py:682\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m outs])\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingular_ \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\scipy\\linalg\\_basic.py:1277\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m   1273\u001b[0m         lwork, rwork, iwork \u001b[38;5;241m=\u001b[39m _compute_lwork(lapack_lwork, m, n,\n\u001b[0;32m   1274\u001b[0m                                              nrhs, cond)\n\u001b[0;32m   1275\u001b[0m         x, s, rank, info \u001b[38;5;241m=\u001b[39m lapack_func(a1, b1, lwork, rwork, iwork,\n\u001b[0;32m   1276\u001b[0m                                        cond, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge in Linear Least Squares\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from lineartree import LinearBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "regr = LinearBoostRegressor(base_estimator=LinearRegression(),n_estimators=10000)\n",
    "train_X = train_data.drop(columns=['price'])\n",
    "train_Y= train_data['price']\n",
    "\n",
    "regr.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 399.2877724443027\n",
      "Mean Squared Error: 678654.8462117971\n",
      "Root Mean Squared Error: 823.8051020792461\n"
     ]
    }
   ],
   "source": [
    "test_X= test_data.drop(columns=['price'])\n",
    "test_Y= test_data['price']\n",
    "y_pred = regr.predict(test_X)\n",
    "\n",
    "#evaluate the model\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_Y, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_Y, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_Y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\super\\AppData\\Local\\Temp\\ipykernel_16864\\2453662047.py:1: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  best_model = predictor.get_model_best()\n",
      "Load pretrained checkpoint: c:\\Users\\super\\OneDrive\\AI experiments\\xtream-challenge\\xtream-ai-assignment-engineer\\notebooks\\autogluon_models\\models\\FTTransformer\\automm_model\\model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: WeightedEnsemble_L2\n",
      "Best Model Info: {'name': 'XGBoost', 'model_type': 'XGBoostModel', 'problem_type': 'regression', 'eval_metric': 'root_mean_squared_error', 'stopping_metric': 'root_mean_squared_error', 'fit_time': 0.7416112422943115, 'num_classes': None, 'quantile_levels': None, 'predict_time': 0.0039980411529541016, 'val_score': -678.0018111547594, 'hyperparameters': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'hyperparameters_fit': {'n_estimators': 145}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None}, 'num_features': 9, 'features': ['carat', 'depth', 'table', 'x', 'y', 'z', 'encoded_cut', 'encoded_clarity', 'encoded_color'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x0000024A6A481120>, 'memory_size': 1628833, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}\n"
     ]
    }
   ],
   "source": [
    "best_model = predictor.get_model_best()\n",
    "best_model_info = predictor.info()['model_info']['XGBoost']\n",
    "\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Best Model Info: {best_model_info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'XGBoost',\n",
       " 'model_type': 'XGBoostModel',\n",
       " 'problem_type': 'regression',\n",
       " 'eval_metric': 'root_mean_squared_error',\n",
       " 'stopping_metric': 'root_mean_squared_error',\n",
       " 'fit_time': 0.7416112422943115,\n",
       " 'num_classes': None,\n",
       " 'quantile_levels': None,\n",
       " 'predict_time': 0.0039980411529541016,\n",
       " 'val_score': -678.0018111547594,\n",
       " 'hyperparameters': {'n_estimators': 10000,\n",
       "  'learning_rate': 0.1,\n",
       "  'n_jobs': -1,\n",
       "  'proc.max_category_levels': 100,\n",
       "  'objective': 'reg:squarederror',\n",
       "  'booster': 'gbtree'},\n",
       " 'hyperparameters_fit': {'n_estimators': 145},\n",
       " 'hyperparameters_nondefault': [],\n",
       " 'ag_args_fit': {'max_memory_usage_ratio': 1.0,\n",
       "  'max_time_limit_ratio': 1.0,\n",
       "  'max_time_limit': None,\n",
       "  'min_time_limit': 0,\n",
       "  'valid_raw_types': ['bool', 'int', 'float', 'category'],\n",
       "  'valid_special_types': None,\n",
       "  'ignored_type_group_special': None,\n",
       "  'ignored_type_group_raw': None,\n",
       "  'get_features_kwargs': None,\n",
       "  'get_features_kwargs_extra': None,\n",
       "  'predict_1_batch_size': None,\n",
       "  'temperature_scalar': None},\n",
       " 'num_features': 9,\n",
       " 'features': ['carat',\n",
       "  'depth',\n",
       "  'table',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z',\n",
       "  'encoded_cut',\n",
       "  'encoded_clarity',\n",
       "  'encoded_color'],\n",
       " 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata at 0x24a6a481120>,\n",
       " 'memory_size': 1628833,\n",
       " 'compile_time': None,\n",
       " 'is_initialized': True,\n",
       " 'is_fit': True,\n",
       " 'is_valid': True,\n",
       " 'can_infer': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold: [ 802.46149363  678.77510657  825.28087451 2224.45779695  931.34579263]\n",
      "Mean RMSE: 1092.4642128587611\n",
      "Standard Deviation of RMSE: 571.6635041462962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Define RMSE scorer\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "# Define cross-validation strategy (e.g., 5-fold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and get RMSE scores\n",
    "rmse_scores = cross_val_score(regr, train_X, train_Y, scoring=rmse_scorer, cv=cv)\n",
    "\n",
    "# Output results\n",
    "print(f'RMSE scores for each fold: {rmse_scores}')\n",
    "print(f'Mean RMSE: {np.mean(rmse_scores)}')\n",
    "print(f'Standard Deviation of RMSE: {np.std(rmse_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(objective='reg:squarederror', n_estimators=10000, random_state=42,learning_rate= 0.1,booster= 'gbtree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores for each fold: [699.52501829 618.82270551 688.58346033 655.96501714 675.34097692]\n",
      "Mean RMSE: 667.6474356370785\n",
      "Standard Deviation of RMSE: 28.404299524541727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\super\\mambaforge\\envs\\autogluon\\lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Define RMSE scorer\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared=False)\n",
    "# Define cross-validation strategy (e.g., 5-fold)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation and get RMSE scores\n",
    "rmse_scores = cross_val_score(model, train_X, train_Y, scoring=rmse_scorer, cv=cv)\n",
    "\n",
    "# Output results\n",
    "print(f'RMSE scores for each fold: {rmse_scores}')\n",
    "print(f'Mean RMSE: {np.mean(rmse_scores)}')\n",
    "print(f'Standard Deviation of RMSE: {np.std(rmse_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
